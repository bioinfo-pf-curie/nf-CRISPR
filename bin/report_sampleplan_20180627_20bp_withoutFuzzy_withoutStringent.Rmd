---
title: "Genome-scale CRISPR-cas9 Knock-Out (GeCKO) QC report"
output:
  html_document:
    toc: true
    depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = FALSE, rows.print=100)
```

```{r results="asis", echo=FALSE}
cat("
<style>
h1 {
  color: orange;
  text-align: center;
}
h2 {
  color: blue;
  border-bottom: 8px solid;
}
</style>
")
```

```{r config, include=FALSE}

library(ggplot2)
library(plotly)
require(dplyr)
require(magrittr)
require(tidyr)
require(DT)

```

| Institut Curie | Report generation date: `r format(Sys.Date(), '%Y-%m-%d')` |
| :------------- | -------------: |
| Report generated by Institut Curie bioinformatic platform | u900.pf.ngs.dm@curie.fr |

#QUALITY CONTROL

From Joung et al. 2016 "Protocol: Genome-scale CRISPR-Cas9 Knockout and Transcriptional Activation Screening" and Li et al. 2015 "Quality
control, modeling, and visualization of CRISPR screens with MAGeCK-VISPR"

```{bash path}
#!/bin/bash
source env_config_calcsub.sh
```
```{r env}
setwd(Sys.getenv("RMDDIR"))
```

```{bash run_count_spacers}
#!/bin/bash
> fastqfiles.list
file=`awk -F',' 'NR==1 {print $3}' SAMPLE_PLAN`
if [ ${file: -3} == ".gz" ]; then
 while IFS=',' read -r id name r1 r2 annot cond time biolrep techrep || [[ -n "$line" ]]; do
  file=$(basename "${r1}" .gz)
  newname="${cond}.${time}.${biolrep}.${techrep}"
  gunzip -c ${r1} >${file}
  echo "${file} ${annot} ${newname}" >>fastqfiles.list
 done < SAMPLE_PLAN
 cat fastqfiles.list | parallel --colsep=' ' --no-notice 'fastqfile={1}; base=$(basename {1}); samplename=${base%.*}; python2 count_spacers_enhanced_20180627_20bp.py -f ${fastqfile} -o count_spacers_"{1}" -i {2}'
else
 while IFS=',' read -r id name r1 r2 annot cond time biolrep techrep || [[ -n "$line" ]]; do
  file=$(basename "${r1}")
  echo "${r1} ${annot} ${file}" >>fastqfiles.list
 done < SAMPLE_PLAN
 cat fastqfiles.list | parallel --colsep=' ' --no-notice 'fastqfile={1}; base=$(basename {1}); samplename=${base%.*}; python2 count_spacers_enhanced_20180627_20bp.py -f ${fastqfile} -o count_spacers_"{3}" -i {2}'
fi
mkdir fuzzy_stringent
mv *.fuzzykey fuzzy_stringent/
mv *.stringent fuzzy_stringent/
```

##Global samples statistics

<span style="color:red" style="font-weigth:bold">Expected :<br/>
Number of reads with guide >= 100 * (sgRNAs library size) (IN NEGATIVE SELECTION PROJECTS ONLY)<br/>
Percentage of mapped reads >= 65%<br/>
Percentage of undetected guides < 2% (IN NEGATIVE SELECTION PROJECTS ONLY)<br/>
Skew ratio of top10 to bottom10 <= 10 (IN NEGATIVE SELECTION PROJECTS ONLY)<br/>
</span>

```{r statistics, warning=FALSE}
sample_plan<-read.csv("SAMPLE_PLAN",header=F,col.names = c("id","name","r1","r2","annot","cond","time","biolrep","techrep"))
options("scipen"=100, "digits"=3)
files = list.files(path = ".",pattern="count_spacers.*\\.stats",full.names = T)
bigtable_stats<-data.frame(lapply(files, read.table, sep=":",header=F,colClasses=c("NULL","character"),stringsAsFactors=F))
colnames(bigtable_stats)<-sub("*.stats", "", sub("count_spacers_", "", basename(files)))
rownames(bigtable_stats)<-make.names(((read.table(files[1],sep=":",header=F,colClasses=c("character","NULL"),stringsAsFactors=F))$V1),unique=TRUE,allow_=TRUE)
require(DT)
bigtable_stats_t<-t(bigtable_stats)
write.csv2(bigtable_stats_t,file="global_stats_table.csv")
DT::datatable(bigtable_stats_t,width=900,options = list(scrollX = TRUE)) %>% formatStyle(colnames(bigtable_stats_t),fontSize= '18px') %>% formatStyle('Perc.Mapped.reads',backgroundColor = styleInterval(65,c('red','green'))) %>% formatStyle('Perc.Undetected.guides',backgroundColor = styleInterval(2,c('green','white'))) %>% formatStyle('Skew.ratio',backgroundColor = styleInterval(10,c('green','white')))
```

<span style="color:red" style="font-weigth:bold">Expected :<br/>
Similar Log10 CPM (Counts Per Million) per guide per sample.
</span>

```{r out, warning=FALSE, message=FALSE, fig.width=10, fig.heigth=round(ncol(bigtable_stats)/2)*600}
files = list.files(path = ".",pattern="count_spacers.*\\.counts$",full.names = T)
bigtable_out<-data.frame(lapply(files, read.table, sep=",",header=F,colClasses=c("NULL","NULL","NULL","integer"),stringsAsFactors=F))
colnames(bigtable_out)<-sub("*.counts", "", sub("count_spacers_", "", basename(files)))
bigtable_out$gene<-make.names((read.table(files[1],sep=",",header=F,colClasses=c("NULL","NULL","character","NULL"),stringsAsFactors=F)[, 1, drop = TRUE]),unique=FALSE,allow_=TRUE)
bigtable_out$sequence<-read.table(files[1], sep=",",header=F,colClasses=c("NULL","character","NULL","NULL"),stringsAsFactors=F)[,1]
bigtable_out$guide<-read.table(files[1], sep=",",header=F,colClasses=c("character","NULL","NULL","NULL"),stringsAsFactors=F)[,1]
rownames(bigtable_out)<-make.names((read.table(files[1],sep=",",header=F,colClasses=c("character",NULL,NULL,"NULL"),stringsAsFactors=F)[, 1, drop = TRUE]),unique=TRUE,allow_=TRUE)
bigtable_out_plusone<-bigtable_out[,1:(dim(bigtable_out)[2]-3)]+1
rownames(bigtable_out_plusone)<-rownames(bigtable_out)
bigtable_cpm<-t(t(bigtable_out_plusone)/rowSums(t(bigtable_out_plusone)))
bigtable_log10cpm<-log10(bigtable_cpm)
require(ggplot2)
require (reshape)
long = melt(bigtable_log10cpm, id.vars= rownames(bigtable_log10cpm))
ggplot(long, aes (value)) + geom_density() + facet_wrap(~X2,ncol=5)
#require(DT)
#DT::datatable(bigtable_log10cpm,width=900,options = list(scrollX = TRUE,scrollY = TRUE))
```

```{r out_fuzzykey, warning=FALSE, message=FALSE, fig.width=10, fig.height=20, eval=FALSE}
files = list.files(path = ".",pattern="count_spacers.*\\.counts.fuzzykey",full.names = T)
bigtable_out_fuzzykey<-data.frame(lapply(files, read.table, sep=",",header=F,colClasses=c("NULL","NULL","NULL","integer"),stringsAsFactors=F))
colnames(bigtable_out_fuzzykey)<-sub("*.counts.fuzzykey", "", sub("count_spacers_", "", basename(files)))
bigtable_out_fuzzykey$gene<-make.names((read.table(files[1],sep=",",header=F,colClasses=c("NULL","NULL","character","NULL"),stringsAsFactors=F)[, 1, drop = TRUE]),unique=FALSE,allow_=TRUE)
bigtable_out_fuzzykey$sequence<-read.table(files[1], sep=",",header=F,colClasses=c("NULL","character","NULL","NULL"),stringsAsFactors=F)[,1]
bigtable_out_fuzzykey$guide<-read.table(files[1], sep=",",header=F,colClasses=c("character","NULL","NULL","NULL"),stringsAsFactors=F)[,1]
rownames(bigtable_out_fuzzykey)<-make.names((read.table(files[1],sep=",",header=F,colClasses=c("character",NULL,NULL,"NULL"),stringsAsFactors=F)[, 1, drop = TRUE]),unique=TRUE,allow_=TRUE)
bigtable_out_fuzzykey_plusone<-bigtable_out_fuzzykey[,1:(dim(bigtable_out_fuzzykey)[2]-3)]+1
rownames(bigtable_out_fuzzykey_plusone)<-rownames(bigtable_out_fuzzykey)
bigtable_cpm_fuzzykey<-t(t(bigtable_out_fuzzykey_plusone)/rowSums(t(bigtable_out_fuzzykey_plusone)))
bigtable_log10cpm_fuzzykey<-log10(bigtable_cpm_fuzzykey)
require(ggplot2)
require (reshape)
long = melt(bigtable_log10cpm_fuzzykey, id.vars= rownames(bigtable_log10cpm_fuzzykey))
#ggplot(long, aes (value)) + geom_density() + facet_wrap(~X2,ncol=5)
#require(DT)
#DT::datatable(bigtable_log10cpm_fuzzykey,width=900,options = list(scrollX = TRUE,scrollY = TRUE))
```

```{r out_stringent, warning=FALSE, message=FALSE, fig.width=10, fig.height=20, eval=FALSE}
files = list.files(path = ".",pattern="count_spacers.*\\.counts.stringent",full.names = T)
bigtable_out_stringent<-data.frame(lapply(files, read.table, sep=",",header=F,colClasses=c("NULL","NULL","NULL","integer"),stringsAsFactors=F))
colnames(bigtable_out_stringent)<-sub("*.counts.stringent", "", sub("count_spacers_", "", basename(files)))
bigtable_out_stringent$gene<-make.names((read.table(files[1],sep=",",header=F,colClasses=c("NULL","NULL","character","NULL"),stringsAsFactors=F)[, 1, drop = TRUE]),unique=FALSE,allow_=TRUE)
bigtable_out_stringent$sequence<-read.table(files[1], sep=",",header=F,colClasses=c("NULL","character","NULL","NULL"),stringsAsFactors=F)[,1]
bigtable_out_stringent$guide<-read.table(files[1], sep=",",header=F,colClasses=c("character","NULL","NULL","NULL"),stringsAsFactors=F)[,1]
rownames(bigtable_out_stringent)<-make.names((read.table(files[1],sep=",",header=F,colClasses=c("character",NULL,NULL,"NULL"),stringsAsFactors=F)[, 1, drop = TRUE]),unique=TRUE,allow_=TRUE)
bigtable_out_stringent_plusone<-bigtable_out_stringent[,1:(dim(bigtable_out_stringent)[2]-3)]+1
rownames(bigtable_out_stringent_plusone)<-rownames(bigtable_out_stringent)
bigtable_cpm_stringent<-t(t(bigtable_out_stringent_plusone)/rowSums(t(bigtable_out_stringent_plusone)))
bigtable_log10cpm_stringent<-log10(bigtable_cpm_stringent)
require(ggplot2)
require (reshape)
long = melt(bigtable_log10cpm_stringent, id.vars= rownames(bigtable_log10cpm_stringent))
#ggplot(long, aes (value)) + geom_density() + facet_wrap(~X2,ncol=5)
#require(DT)
#DT::datatable(bigtable_log10cpm_stringent,width=900,options = list(scrollX = TRUE,scrollY = TRUE))
```

```{bash fastqc, echo=FALSE, warning=FALSE, message=FALSE}
#fastqc -q -t 6 -o . data/*/*.fastq
cat fastqfiles.list | parallel --colsep=' ' --no-notice 'fastqc -q -o . {1}'
```
```{r readfastqc, echo=FALSE, warning=FALSE, message=FALSE}
require(rutilsfastqc)
QC<-readFastqcZips(path=".",glob="*_fastqc.zip")
```
<span style="color:red" style="font-weigth:bold">
Expected :<br/>
Similar GC content distribution of the sequencing reads for all samples from same library.
</span>
```{r fastqc_gc, warning=FALSE, message=FALSE, fig.width=10, fig.heigth=round(ncol(bigtable_stats)/2)*600}
#names(QC)<-substr(names(QC),1,nchar(names(QC))-3)
require(purrr)
require(dplyr)
QC_map<-map2(.x = QC, .y = names(QC), .f = ~map_at(.x, .f = mutate, sample = .y, .at = c("Per_sequence_GC_content","Per_base_sequence_quality")))
QC_cat_gc<-bind_rows(lapply(QC_map, "[[", "Per_sequence_GC_content"))
ggplot(QC_cat_gc, aes(x=`GC Content`, y= Count, color=sample)) + geom_line()
```
<span style="color:red" style="font-weigth:bold">
<br/>Expected :<br/>
Median base quality distribution of the sequencing reads >= 25.
</span>
```{r fastqc_bq, fig.width=10, fig.height=10}
QC_cat_bq<-bind_rows(lapply(QC_map, "[[", "Per_base_sequence_quality"))
ggplot(QC_cat_bq, aes(x = Base, ymin = `10th Percentile`, lower = `Lower Quartile`, middle = `Median`, upper = `Upper Quartile`, ymax = `90th Percentile`)) + geom_boxplot(stat="identity",fill = "yellow")+ facet_wrap(~sample,ncol=5) + ylim(0,40)
```
</br><a href="#">Back to top</a>

##Guides Count Results (First lines + link to complete table)

```{r table, message=FALSE, warning=FALSE}
require(DT)
save.image(file="report.RData")
DT::datatable(head(bigtable_out[,1:(dim(bigtable_out)[2]-1)]), width=900,options = list(scrollX = TRUE,scrollY = TRUE))
write.csv2(bigtable_out[,1:(dim(bigtable_out)[2]-1)],file="global_counts_table.csv")
```
[global_counts_table.csv](global_counts_table.csv)
</br></br><a href="#">Back to top</a>
